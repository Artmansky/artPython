{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a758b0c8-ca43-45d6-b634-f45d0a7af2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e7c856-d328-4d9d-8fc9-2c6a5ba49043",
   "metadata": {},
   "outputs": [],
   "source": [
    "class artStylesDataset(Dataset):\n",
    "    def __init__(self,data_dir,transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eab4136-1e90-445e-9bc6-724fb5a684d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtsClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ArtsClassifier,self).__init__()\n",
    "        self.base_model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        \n",
    "        enet_out_size = 1280\n",
    "        self.classifier = nn.Linear(enet_out_size,num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f656c07-b600-4658-b953-fb5a1f5dcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((464,600)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainDataset = artStylesDataset(\"./Data\", transform=transform)\n",
    "validDataset = artStylesDataset(\"./Valid\", transform=transform)\n",
    "testDataset = artStylesDataset(\"./Test\", transform=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainDataset,batch_size=32,shuffle=True)\n",
    "validLoader = DataLoader(validDataset,batch_size=32,shuffle=True)\n",
    "testLoader = DataLoader(testDataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5bf56-596f-4766-91b4-2608fa326716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70957622007e45488c284f22d9409f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training progress:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epoch = 5\n",
    "trainLoss,valLoss = [], []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ArtsClassifier(num_classes=4)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(\"Training session start\")\n",
    "    for images,labels in tqdm(trainLoader,desc=\"Training progress\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss *= loss.item() * labels.size(0)\n",
    "    train_loss = running_loss/len(trainLoader.dataset)\n",
    "    trainLoss.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images,labels in tqdm(validLoader,desc=\"Validation progress\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "    val_loss = running_loss / len(valLoader.dataset)\n",
    "    valLoss.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713de301-dc22-4331-95e6-f084f659b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainLoss, label=\"Training loss\")\n",
    "plt.plot(valLoss, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a27b0e-9123-48f4-b9ac-c2abf40723b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
