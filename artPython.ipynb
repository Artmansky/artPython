{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a758b0c8-ca43-45d6-b634-f45d0a7af2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e7c856-d328-4d9d-8fc9-2c6a5ba49043",
   "metadata": {},
   "outputs": [],
   "source": [
    "class artStylesDataset(Dataset):\n",
    "    def __init__(self,data_dir,transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eab4136-1e90-445e-9bc6-724fb5a684d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtsClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ArtsClassifier,self).__init__()\n",
    "        self.base_model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        \n",
    "        enet_out_size = 1280\n",
    "        self.classifier = nn.Linear(enet_out_size,num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f656c07-b600-4658-b953-fb5a1f5dcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((464,600)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "model_path = \"artPython_model.pkl\"\n",
    "\n",
    "data_dir = './Data'\n",
    "dataset = artStylesDataset(data_dir, transform)\n",
    "\n",
    "trainDataset = artStylesDataset(\"./Data\", transform=transform)\n",
    "validDataset = artStylesDataset(\"./Valid\", transform=transform)\n",
    "testDataset = artStylesDataset(\"./Test\", transform=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainDataset,batch_size=32,shuffle=True)\n",
    "validLoader = DataLoader(validDataset,batch_size=32,shuffle=True)\n",
    "testLoader = DataLoader(testDataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4e59d3-3210-4a68-9330-1e1dc225c170",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (687496552.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ArtsClassifier(num_classes=4)\n",
    "model.to(device)\n",
    "\n",
    "try:\n",
    "    with open(model_path, 'rb') as file:  \n",
    "        model = pickle.load(file)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5bf56-596f-4766-91b4-2608fa326716",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 5\n",
    "trainLoss,valLoss = [], []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "print(\"Training session start\")\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images,labels in tqdm(trainLoader,desc=\"Training progress\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss/len(trainLoader.dataset)\n",
    "    trainLoss.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images,labels in tqdm(validLoader,desc=\"Validation progress\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "    val_loss = running_loss / len(validLoader.dataset)\n",
    "    valLoss.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch} - Train loss: {train_loss}, Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713de301-dc22-4331-95e6-f084f659b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainLoss, label=\"Training loss\")\n",
    "plt.plot(valLoss, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301fd46-7510-404a-9b03-449f064b5238",
   "metadata": {},
   "source": [
    "Saving/Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bad27-83ca-4562-8083-57446eeb1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8d482-11c5-4abd-b7ec-6fa0320cea11",
   "metadata": {},
   "source": [
    "Simple model test below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275e59c-1579-4026-946d-fa1bf313534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image, transform(image).unsqueeze(0)\n",
    "\n",
    "def predict(model, image_tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    return probabilities.cpu().numpy().flatten()\n",
    "\n",
    "def visualize_predictions(original_image, probabilities, class_names):\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Display image\n",
    "    axarr[0].imshow(original_image)\n",
    "    axarr[0].axis(\"off\")\n",
    "    \n",
    "    # Display predictions\n",
    "    axarr[1].barh(class_names, probabilities)\n",
    "    axarr[1].set_xlabel(\"Probability\")\n",
    "    axarr[1].set_title(\"Class Predictions\")\n",
    "    axarr[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_image = \"./Test/postimpressionsm/vase-with-peonies.png\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((464, 600)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "original_image, image_tensor = preprocess_image(test_image, transform)\n",
    "probabilities = predict(model, image_tensor, device)\n",
    "\n",
    "class_names = dataset.classes \n",
    "visualize_predictions(original_image, probabilities, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200c85c-ce1f-432c-8bc0-284e47efe489",
   "metadata": {},
   "outputs": [],
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
