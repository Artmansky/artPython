{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e79324-c512-44e1-9452-20148ca1c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision timm matplotlib tqdm pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a758b0c8-ca43-45d6-b634-f45d0a7af2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "import pickle\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e7c856-d328-4d9d-8fc9-2c6a5ba49043",
   "metadata": {},
   "outputs": [],
   "source": [
    "class artStylesDataset(Dataset):\n",
    "    def __init__(self,data_dir,transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eab4136-1e90-445e-9bc6-724fb5a684d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtsClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ArtsClassifier,self).__init__()\n",
    "        self.base_model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        \n",
    "        enet_out_size = 1280\n",
    "        self.classifier = nn.Linear(enet_out_size,num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f656c07-b600-4658-b953-fb5a1f5dcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((464,300)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "num_epoch = 15 #Should work fine between 5 to 20\n",
    "model_path = \"./Results/artPythonModel-\" + str(num_epoch) + \"-epochs.pkl\"\n",
    "plot_path = \"./Results/artPythonPlot-\" + str(num_epoch) + \"-epochs.png\"\n",
    "\n",
    "trainDataset = artStylesDataset(\"./Data\", transform=transform)\n",
    "validDataset = artStylesDataset(\"./Valid\", transform=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainDataset,batch_size=16,shuffle=True)\n",
    "validLoader = DataLoader(validDataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4e59d3-3210-4a68-9330-1e1dc225c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ArtsClassifier(num_classes=6)\n",
    "model.to(device)\n",
    "\n",
    "try:\n",
    "    with open(model_path, 'rb') as file:  \n",
    "        model = pickle.load(file)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c5bf56-596f-4766-91b4-2608fa326716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training skipped - model loaded from file\n"
     ]
    }
   ],
   "source": [
    "trainLoss,valLoss = [], []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model.parameters(),lr=0.002)\n",
    "\n",
    "print(\"Training session start\")\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images,labels in tqdm(trainLoader,desc=\"Training progress\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss/len(trainLoader.dataset)\n",
    "    trainLoss.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images,labels in tqdm(validLoader,desc=\"Validation progress\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "    val_loss = running_loss / len(validLoader.dataset)\n",
    "    valLoss.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch} - Train loss: {train_loss}, Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713de301-dc22-4331-95e6-f084f659b372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot not generated - model loaded from file\n"
     ]
    }
   ],
   "source": [
    "plt.plot(trainLoss, label=\"Training loss\")\n",
    "plt.plot(valLoss, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "saved = plt.gcf()\n",
    "plt.show()\n",
    "saved.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301fd46-7510-404a-9b03-449f064b5238",
   "metadata": {},
   "source": [
    "Saving/Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0bad27-83ca-4562-8083-57446eeb1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'wb') as file:  \n",
    "    pickle.dump(model, file)\n",
    "    print(\"Pickle file saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70110eaf-1c37-4fd8-b928-4059b98cf7b1",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
